{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rXswkJ_zz4kV"
      },
      "id": "rXswkJ_zz4kV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/vgg_24\n"
      ],
      "metadata": {
        "id": "PHPCm4no2ENt"
      },
      "id": "PHPCm4no2ENt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f171d9",
      "metadata": {
        "id": "62f171d9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from utils import check_accuracy, load_checkpoint, save_checkpoint, make_prediction\n",
        "import config\n",
        "from dataset import MyImageFolder\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "ls=os.listdir('/content/drive/MyDrive/cars_classification/cars_classification_dataset/train')\n",
        "len(ls)"
      ],
      "metadata": {
        "id": "eKich91L2fHN"
      },
      "id": "eKich91L2fHN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d06c0f",
      "metadata": {
        "id": "62d06c0f"
      },
      "outputs": [],
      "source": [
        "train_ds = MyImageFolder(root_dir=\"/content/drive/MyDrive/cars_classification/cars_classification_dataset/train\", transform=config.train_transforms)\n",
        "val_ds = MyImageFolder(root_dir=\"/content/drive/MyDrive/cars_classification/cars_classification_dataset/valid\", transform=config.val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS,pin_memory=config.PIN_MEMORY, shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(val_ds, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS,pin_memory=config.PIN_MEMORY,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d574989d",
      "metadata": {
        "id": "d574989d"
      },
      "outputs": [],
      "source": [
        "#Reference taken for the code \n",
        "# Architecture Structure referenced from and modified for ourselves\n",
        "# Programmed by Aladdin Persson(2021)\n",
        "# https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/CNN_architectures/pytorch_vgg_implementation.py\n",
        "\n",
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\", ],\n",
        "    \"VGG19\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\", ],\n",
        "    \"VGG24\": [64, 64, 64, \"M\", 128, 128, 128, \"M\", 256, 256, 256, 256, 256, \"M\", 512, 512, 512, 512, 512, \"M\", 512, 512, 512, 512, 512, \"M\", ],\n",
        "}\n",
        "\n",
        "device='cuda'\n",
        "class VGG_net(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=1000):\n",
        "        super(VGG_net, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG24\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85a5d9a",
      "metadata": {
        "id": "b85a5d9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler, device):\n",
        "    i = 0\n",
        "    loss = 0\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward\n",
        "       \n",
        "        scores = model(data)\n",
        "        loss = loss_fn(scores, targets.to(torch.int64))\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "    model.train()\n",
        "    return loss, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39630925",
      "metadata": {
        "id": "39630925"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model = VGG_net(in_channels=3, num_classes=196).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "data_training = {}\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    loss, model = train_fn(train_loader, model, optimizer, loss_fn, scaler, config.DEVICE)\n",
        "    print('loss is : ',loss)\n",
        "\n",
        "    checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "    data_training[f'epoch_{epoch+1}'] = {'loss': float(loss)}\n",
        "    with open('training.json', 'w') as j_file:\n",
        "        json.dump(data_training, j_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c0f00d",
      "metadata": {
        "id": "77c0f00d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "with open('training.json','rb') as file:\n",
        "   js = json.load(file)\n",
        "\n",
        "key_list = []\n",
        "ls = list(js.keys())\n",
        "for key in ls:\n",
        "    # print(js[key]['loss'])\n",
        "    key_list.append(js[key]['loss'])\n",
        "print(key_list)\n",
        "key_list = sorted(key_list, reverse=True)\n",
        "\n",
        "\n",
        "# Define X and Y variable data\n",
        "plt.plot( key_list, 'g', label='Training loss')\n",
        "plt.title('Complete Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('vgg24_cars_training.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}